from pymongo import MongoClient
#from bson.objectid import ObjectId
from pandas import DataFrame
import pandas as pd
from ast import literal_eval

output_path = '/media/cuckoohost/TCC/Codigos/csvs/'

def helper_dynamic(process_list, calls_collection):
    processes_api_calls = []
    for process in process_list:
        this_process_api_calls = []
        calls_list = process['calls'] #o banco divide armazena a cada 100 calls em entradas diferentes
        for call_id in calls_list:
            api_calls_query = list(calls_collection.find({"_id": call_id},{"pid":1,"_id":1, "calls":1}))
            api_calls_df = pd.DataFrame(api_calls_query)
            for api_calls_list in api_calls_df['calls']:
                for api_calls in api_calls_list:
                    this_process_api_calls.append(api_calls['api'])
        processes_api_calls.append(this_process_api_calls)
    return processes_api_calls

def get_database():
    CONNECTION_STRING = "mongodb://localhost:27017"

    client = MongoClient(CONNECTION_STRING)
    return client['cuckoo']

def batched(cursor, batch_size):
    batch = []
    for doc in cursor:
        batch.append(doc)
        if batch and not len(batch) % batch_size:
            yield batch
            batch = []
    if batch:
        yield batch

if __name__ == "__main__":   

    dbname = get_database()
    
    analysis_collection = dbname["analysis"]
    calls_collection = dbname["calls"]

    analysis_df_list = []
    for contador in range(0,6):
        findex = 1+contador*1000
        lindex = contador*1000+1000
        print(findex, lindex)
        samples_list = list(analysis_collection.find({"info.id": {'$gte': findex, '$lte': lindex}, "isTest":True},{"info.id":1,"_id":0, "isMalware":1, "objdump.opcodes_objdump":1}))
        #df = pd.json_normalize(samples_list)
        #for column in df.columns:
        #    print(column)
        df = DataFrame(samples_list)
        df.to_csv(output_path + 'objdump/objdump{}_test.csv'.format(contador), index=False)
        print(df.info(memory_usage="deep"))

    for contador in range(0,6):
        findex = 1+contador*1000
        lindex = contador*1000+1000
        print(findex, lindex)
        samples_list = list(analysis_collection.find({"info.id": {'$gte': findex, '$lte': lindex}, "isTest":True},{"_id":0, "isMalware":1, "static.elf":1, "strings":1}))
        df = pd.json_normalize(samples_list)
        
        #keep only feature columns
        feature_columns_list = ['static.elf.relocations','static.elf.dynamic_tags','static.elf.program_headers','static.elf.symbol_tables','static.elf.section_headers','static.elf.file_header.number_of_section_headers','static.elf.file_header.magic','static.elf.file_header.number_of_program_headers',
                        'static.elf.file_header.size_of_this_header','static.elf.file_header.flags','static.elf.file_header.size_of_section_headers',
                        'static.elf.file_header.type','static.elf.file_header.entry_point_address','static.elf.file_header.size_of_program_headers',
                        'static.elf.file_header.start_of_section_headers','static.elf.file_header.start_of_program_headers','static.elf.file_header.data','strings','isMalware']
        
        df = df[feature_columns_list]

        #rename columns
        rename_columns_dict = {'static.elf.relocations':'relocations','static.elf.dynamic_tags':'dynamic_tags','static.elf.program_headers':'program_headers',
                        'static.elf.symbol_tables':'symbol_tables','static.elf.section_headers':'section_headers',
                        'static.elf.file_header.number_of_section_headers':'number_of_section_headers','static.elf.file_header.magic':'magic_number',
                        'static.elf.file_header.number_of_program_headers':'number_of_program_headers','static.elf.file_header.size_of_this_header':'size_of_this_header',
                        'static.elf.file_header.flags':'flags','static.elf.file_header.size_of_section_headers':'size_of_section_headers','static.elf.file_header.type':'type',
                        'static.elf.file_header.entry_point_address':'entry_point_address','static.elf.file_header.size_of_program_headers':'size_of_program_headers',
                        'static.elf.file_header.start_of_section_headers':'start_of_section_headers','static.elf.file_header.start_of_program_headers':'start_of_program_headers',
                        'static.elf.file_header.data':'endianess'}
        
        df = df.rename(rename_columns_dict, axis='columns')

        #for column in df.columns:
        #    print(column)
        df.to_csv(output_path + 'static/static{}_test.csv'.format(contador), index=False)
        print(df.info(memory_usage="deep"))
    
    analysis_df_list = []
    for contador in range(0,6):
        findex = 1+contador*1000
        lindex = contador*1000+1000
        print(findex, lindex)
        samples_list = list(analysis_collection.find({"info.id": {'$gte': findex, '$lte': lindex}, "isTest":True},{"info.id":1,"_id":0, "isMalware":1, "behavior":1}))
        df = pd.json_normalize(samples_list)
        #for process_list in df['behavior.processes']:
        #    for process in process_list:
        #        calls_list = process['calls']
        #        for call in calls_list:
        #            print(call)
        df['calls_list'] = [[] if 'nan' in str(x) else helper_dynamic(x, calls_collection) for x in df['behavior.processes']]
        #print(df.head())
        #for column in df.columns:
        #    print(column)
        df = DataFrame(samples_list)
        df.to_csv(output_path + 'dynamic/dynamic{}_test.csv'.format(contador), index=False)
        print(df.info(memory_usage="deep"))